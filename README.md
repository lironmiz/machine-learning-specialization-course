<a name="readme-top"></a>
<h1 align="center"> ⚡ machine-learning-specialization-course ⚡ </h1>

<img src="https://i.imgur.com/dBaSKWF.gif" height="50" width="100%">

Master fundamental AI concepts and develop practical machine learning skills in the beginner-friendly, 3-course program by AI visionary Andrew Ng the coure is in coursera and brouget by stanford universty and deeplearning.AI

The Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. This beginner-friendly program will teach you the fundamentals of machine learning and how to use these techniques to build real-world AI applications. 

This Specialization is taught by Andrew Ng, an AI visionary who has led critical research at Stanford University and groundbreaking work at Google Brain, Baidu, and Landing.AI to advance the AI field.

This 3-course Specialization is an updated version of Andrew’s pioneering Machine Learning course, rated 4.9 out of 5 and taken by over 4.8 million learners since it launched in 2012. 

It provides a broad introduction to modern machine learning, including supervised learning (multiple linear regression, logistic regression, neural networks, and decision trees), unsupervised learning (clustering, dimensionality reduction, recommender systems), and some of the best practices used in Silicon Valley for artificial intelligence and machine learning innovation (evaluating and tuning models, taking a data-centric approach to improving performance, and more.)

By the end of this Specialization, you will have mastered key concepts and gained the practical know-how to quickly and powerfully apply machine learning to challenging real-world problems. If you’re looking to break into AI or build a career in machine learning, the new Machine Learning Specialization is the best place to start.

<!-- Badges -->
<p>
  <a href="https://github.com/lironmiz/
machine-learning-specialization-course/graphs/contributors">
    <img src="https://img.shields.io/github/contributors/lironmiz/
machine-learning-specialization-course" alt="contributors" />
  </a>
  <a href="">
    <img src="https://img.shields.io/github/last-commit/lironmiz/
machine-learning-specialization-course" alt="last update" />
  </a>
  <a href="https://github.com/lironmiz/
machine-learning-specialization-course/network/members">
    <img src="https://img.shields.io/github/forks/lironmiz/
machine-learning-specialization-course" alt="forks" />
  </a>
  <a href="https://github.com/lironmiz/
machine-learning-specialization-course/stargazers">
    <img src="https://img.shields.io/github/stars/ladunjexa/nand2tetrisCourse" alt="stars" />
  </a>
  <a href="https://github.com/lironmiz/
machine-learning-specialization-course/issues/">
    <img src="https://img.shields.io/github/issues/lironmiz/
machine-learning-specialization-course" alt="open issues" />
  </a>
  <a href="https://github.com/lironmiz/
machine-learning-specialization-course/language count/">
    <img src="https://img.shields.io/github/languages/count/lironmiz/
machine-learning-specialization-course" alt="language count" />
  </a>
</p>

 ![](https://img.shields.io/tokei/lines/github/lironmiz/
machine-learning-specialization-course?color=blue&label=Lines%20of%20Code)
![Size](https://img.shields.io/github/repo-size/lironmiz/
machine-learning-specialization-course?color=red&label=Repo%20Size%20)
 <img src="https://img.shields.io/github/languages/top/lironmiz/
machine-learning-specialization-course" alt="top language" />

<!-- Table of Contents -->
<details>

<summary>

# :notebook_with_decorative_cover: Table of Contents

</summary>

- [The Graduation Certificate](#star2-the-graduation-certificate)
- [Course Material](#books-course-material) 
- [Course Summary](#alien-course-summary) 
- [Contact](#handshake-contact)
- [Acknowledgements](#gem-acknowledgements)
- [About the authors](#telephone-about-the-authors)
- [Course Status](#octocat-project-status)

</details>  

<!-- The Graduation Certificate -->
# :star2: The Graduation Certificate 

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<!-- Course Material -->
# :books: Course Material
 
    + Introduction to machine learning
    + Supervised learning
    + Regression
    + Classification
    + Unsupervised learning 
    + Linear regression
    + Cost function 
    + Gradient descent 
    + Logistic regression
    + Decision boundary
    + Neural networks 
    + Forward propagation
    + TensorFlow
    
<p align="right">(<a href="#readme-top">back to top</a>)</p>

<!-- The Course Summary -->

# :alien: Course Summary

## 1. TABLE OF CONTENTS
  - [1. TABLE OF CONTENTS](#1-table-of-contents)
  - [2. APPLICATIONS OF MACHINE LEARNING](#2-applications-of-machine-learning)
  - [3. MACHINE LEARNING DEFINITION ](#3-machine-learning-definition)
  - [4. SUPERVISED LEARNING](#4-supervised-learning)
  - [5. REGRESSION](#5-regression)
  - [6. CLASSIFICATION](#6-classification)
  - [7. UNSUPERVISED LEARNING](#7-unsupervised-learning)
  - [8. LINEAR REGRESSION](#8-linear-regression)
  - [9. COST FUNCTION](#9-cost-function)
  - [10. GRADIENT DESCENT](#10-gradient-descent)
  - [11. MULTUPLE FEATURES](#11-multiple-features)
  - [12. FEATURE SCALING](#12-feature-scaling)
  - [13. FEATURE ENGINEERING](#13-feature-engineering)
  - [14. SIGMOID FUNCTION](#14-sigmoid-function)
  - [15. LOGISTIC REGRESSION](#15-logistic-regerssion)
  - [16. DECISION BOUNDARY](#16-decision-boundary)
  - [17. OVERFITTING](#17-overfitting)
  - [18. ADDRESSING OVERFITTING](#18-addressing-overfitting)
  - [19. NEURAL NETWORKS](#19-neural-networks)
  - [20. FORWARD PROPAGATION](#20-forward-propagation)
  - [21. TENSORFLOW](#21-tensorflow)
  
  forward propagation 
  
## 2. APPLICATIONS OF MACHINE LEARNING

![OmgWowGIF](https://user-images.githubusercontent.com/91504420/230409706-97176a59-d938-4897-8bb8-71f28b00f427.gif)

Machine learning is a field of artificial intelligence that focuses on building algorithms that can automatically learn from and make predictions on data. Here is a brief summary of some common applications of machine learning:

 + Image and speech recognition: Machine learning algorithms can be trained to recognize images and speech with high accuracy, allowing for applications such as image search, facial recognition, and voice assistants.

  + Natural language processing: Machine learning algorithms can analyze and understand human language, allowing for applications such as language translation, sentiment analysis, and chatbots.

  + Fraud detection: Machine learning algorithms can detect patterns in financial transactions and identify fraudulent behavior, helping to prevent financial loss.

  + Recommendation systems: Machine learning algorithms can analyze user behavior and preferences to make personalized recommendations, such as in e-commerce and content streaming platforms.

  + Healthcare: Machine learning algorithms can analyze medical data to help diagnose diseases, predict patient outcomes, and develop personalized treatment plans.

  + Autonomous vehicles: Machine learning algorithms are used to help autonomous vehicles make decisions and navigate their surroundings.

  + Predictive maintenance: Machine learning algorithms can analyze sensor data from machines to predict when maintenance is needed, helping to prevent downtime and reduce costs.

## 3. MACHINE LEARNING DEFINITION

![JustBasicStuffNormalGIF](https://user-images.githubusercontent.com/91504420/230414731-e129d8a6-e1dd-4d7a-9057-051b4e137e85.gif)

Machine learning is a subfield of artificial intelligence that involves developing algorithms that can learn from data and make predictions or decisions based on that learning. It uses statistical techniques to enable computers to improve at a task over time, without being explicitly programmed to do so. The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Applications of machine learning include image and speech recognition, natural language processing, fraud detection, recommendation systems, healthcare, autonomous vehicles, and predictive maintenance.

## 4. SUPERVISED LEARNING

![ThisIsAnImpressiveResultDerekMullerGIF](https://user-images.githubusercontent.com/91504420/230476420-78789a70-70f7-4d58-a121-9254885c3f7b.gif)

Supervised learning is a type of machine learning in which an algorithm learns to make predictions or decisions by training on a labeled dataset. The labeled dataset consists of input data paired with corresponding output data, called labels or target variables. During training, the algorithm learns to map inputs to outputs by adjusting its internal parameters using various optimization techniques. Once trained, the algorithm can be used to make predictions on new, unseen data. Supervised learning is used in a wide range of applications, such as image recognition, speech recognition, natural language processing, and recommendation systems.

![image](https://user-images.githubusercontent.com/91504420/230415649-6cff3999-2c12-4a24-a229-807266ee7e95.png)

## 5. REGRESSION

![LinearRegressionGIF](https://user-images.githubusercontent.com/91504420/230476966-f6a148a8-2293-46f7-9002-aeb7e28953ab.gif)


Regression is a type of supervised learning algorithm used for predicting continuous numerical values. The goal of regression is to build a model that can accurately predict the value of a dependent variable (also called the response variable) based on one or more independent variables (also called predictor variables or features). The most commonly used regression models include linear regression, polynomial regression, and logistic regression. Regression is widely used in various fields such as finance, economics, engineering, and social sciences for predicting outcomes based on historical data.

![image](https://user-images.githubusercontent.com/91504420/230477065-f868fa30-1d16-4c76-8fd7-dc85bced96f6.png)

## 6. CLASSIFICATION

![TheTruthIsTheTruthJulietteFairmontGIF](https://user-images.githubusercontent.com/91504420/230478296-02fc6601-92f6-43f1-88a9-db44a03da90e.gif)

Classification is a type of supervised learning algorithm used for predicting categorical values. The goal of classification is to build a model that can accurately classify input data into one of several predefined categories or classes. The input data is typically represented as a set of features, and the model learns to map the features to the corresponding class label based on labeled training data. The most commonly used classification algorithms include decision trees, logistic regression, support vector machines, and neural networks. Classification is widely used in various applications such as spam detection, fraud detection, sentiment analysis, and image recognition.

![image](https://user-images.githubusercontent.com/91504420/230478341-3a7a826b-a3c8-4b50-95ec-fab06b315c00.png)

## 7. UNSUPERVISED LEARNING

![ThePatternHereIsClearSteveKornackiGIF](https://user-images.githubusercontent.com/91504420/230479195-ced69b45-6e66-42aa-a335-b8de63d842da.gif)

Unsupervised learning is a type of machine learning in which the algorithm learns to identify patterns or relationships in input data without any labeled target variables. The algorithm is provided with a set of input data and must discover any underlying structure or patterns on its own. Unsupervised learning is often used for tasks such as clustering, dimensionality reduction, and anomaly detection. Clustering algorithms group similar data points together based on their features, while dimensionality reduction techniques aim to reduce the number of features in the input data. Anomaly detection algorithms identify unusual data points or patterns that do not fit the normal distribution of the input data. Unsupervised learning is widely used in fields such as finance, biology, and social network analysis.

![image](https://user-images.githubusercontent.com/91504420/230480167-dc228ffe-0069-4d60-acee-2f8a8a8001b7.png)

## 8. LINEAR REGRESSION

![SecantLineConvergingToTangentLineAnimationGIF](https://user-images.githubusercontent.com/91504420/230501458-ef15c631-16f7-471f-81d4-737523101c32.gif)

Linear regression is a statistical method used to model the relationship between a dependent variable (usually denoted by "y") and one or more independent variables (usually denoted by "x"). The relationship between the variables is assumed to be linear, which means that a change in the independent variable(s) results in a proportional change in the dependent variable.

In other words, linear regression tries to find the line of best fit that describes the relationship between the variables. This line can be used to predict the value of the dependent variable given the value(s) of the independent variable(s).

Linear regression is widely used in various fields, including finance, economics, biology, and engineering. It can be used for both simple linear regression, where there is only one independent variable, and multiple linear regression, where there are several independent variables.

The method involves estimating the coefficients of the line of best fit using a technique called Ordinary Least Squares (OLS). The OLS method minimizes the sum of the squared differences between the predicted and actual values of the dependent variable, which results in the line of best fit that describes the relationship between the variables.

![image](https://user-images.githubusercontent.com/91504420/230510882-b59aa22f-27f8-461f-a25a-cc3ffb48429f.png)

![image](https://user-images.githubusercontent.com/91504420/230511352-158675eb-1100-4c6f-a871-35150b573bc0.png)

## 9. COST FUNCTION

![GetBetterTrevorMcnealGIF](https://user-images.githubusercontent.com/91504420/230512420-e8e7fa85-6dd7-4f93-9091-11ee9abdc920.gif)

The cost function, also known as the loss function or objective function, is a mathematical function that measures the difference between the predicted output and the actual output for a given set of input data. Its purpose is to quantify how well a machine learning algorithm is performing and guide the optimization process of the model parameters to minimize the errors in the predictions. The choice of the cost function depends on the specific problem being solved, and there are different types of cost functions, such as mean squared error, cross-entropy, hinge loss, etc. The cost function plays a crucial role in training machine learning models and is typically optimized using techniques such as gradient descent.

![image](https://user-images.githubusercontent.com/91504420/230512514-cc8560d7-698b-49e6-88a4-17421ca9c72c.png)

### Examples: 

![image](https://user-images.githubusercontent.com/91504420/230513114-3fd7c578-3042-41b1-9aba-b033d18b7e0b.png)

![image](https://user-images.githubusercontent.com/91504420/230513482-1c282e4b-a864-4384-a210-369c5e519510.png)

![image](https://user-images.githubusercontent.com/91504420/230513851-14f1af72-8eb6-4ae9-8182-485f19a09713.png)

## 10. GRADIENT DESCENT

![YogscastLydiaGIF](https://user-images.githubusercontent.com/91504420/230588948-1c68af05-682f-48bb-85aa-6b4b4114e5d7.gif)

Gradient descent is an optimization algorithm used to minimize the cost function of a machine learning model. It is a first-order optimization algorithm, meaning that it takes into account the first derivative of the cost function, which is also known as the gradient.

The basic idea behind gradient descent is to iteratively update the parameters of the model in the direction of the negative gradient of the cost function. This means that the algorithm tries to find the minimum of the cost function by taking small steps in the direction of the steepest slope.

The algorithm starts with an initial set of parameter values and iteratively updates them until it reaches a minimum of the cost function. There are different variations of gradient descent, including batch gradient descent, stochastic gradient descent, and mini-batch gradient descent.

Gradient descent is widely used in various machine learning models, such as linear regression, logistic regression, and neural networks. It is a powerful optimization algorithm that can converge to a minimum of the cost function quickly, especially when combined with other optimization techniques such as momentum, adaptive learning rates, and regularization.

![image](https://user-images.githubusercontent.com/91504420/230515012-cb10c228-009c-4e7e-b702-100cea0bbb64.png)

![image](https://user-images.githubusercontent.com/91504420/230515340-389657fb-5c8b-4451-a42d-4a16641d3ea3.png)

![image](https://user-images.githubusercontent.com/91504420/230515559-655eb343-df52-47e8-bbb1-34b5c9a3876d.png)

![image](https://user-images.githubusercontent.com/91504420/230595144-b0bc313e-44cd-45b0-a7ec-e4cf39b6da5b.png)


## 11. MULTUPLE FEATURES

![MadroxMultipleManGIF](https://user-images.githubusercontent.com/91504420/230588779-15bcc10b-8bde-4c01-b34c-76b075402b5e.gif)

multiple features refer to the variables or input data used to make predictions or classifications. These features are often represented as columns in a dataset and can be numerical, categorical, or textual in nature.

Feature selection and engineering are crucial steps in machine learning as they determine the quality of the model's predictions. Selecting the most relevant and informative features helps to improve the model's accuracy and efficiency.

Common techniques used in feature engineering include normalization, scaling, one-hot encoding, and dimensionality reduction. Additionally, feature selection methods such as correlation analysis, recursive feature elimination, and tree-based methods can be used to identify the most important features for a given problem.

![image](https://user-images.githubusercontent.com/91504420/230589099-e1013003-3bd8-473e-8b30-d5a07995de04.png)

![image](https://user-images.githubusercontent.com/91504420/230589681-c6e571cb-441d-4960-9eb2-4939ba0518ad.png)

## 12. FEATURE SCALING

![LookAtTheScaleHereDaveOlsonGIF](https://user-images.githubusercontent.com/91504420/230591622-eed0aa7f-b500-4202-b973-4db846c2a8a3.gif)

Feature scaling is a technique used in machine learning to transform the range of input variables to a common scale. This is done to ensure that no variable has a disproportionate impact on the model due to its larger magnitude or range.

Common methods for feature scaling include normalization, which rescales the data to a range of 0 to 1, and standardization, which transforms the data to have a mean of 0 and a standard deviation of 1. These techniques can be applied to both numerical and categorical variables.

Proper feature scaling can lead to faster and more accurate model training, particularly for algorithms that use distance-based measures, such as k-nearest neighbors and support vector machines.

![image](https://user-images.githubusercontent.com/91504420/230591835-ceddcfa2-99c1-4a82-80c1-4a8d47f2110a.png)

![image](https://user-images.githubusercontent.com/91504420/230592028-084f759a-a9b6-406e-974f-9dc6383d7c66.png)

![image](https://user-images.githubusercontent.com/91504420/230593219-caaa4989-ad80-4e8c-838d-4861e6ce3262.png)

![image](https://user-images.githubusercontent.com/91504420/230593667-fca2c436-8174-42b7-b4a7-65a7789f46ee.png)

![image](https://user-images.githubusercontent.com/91504420/230594056-e5bb4502-d326-41de-ab39-7a14a1b6d479.png)

## 13. FEATURE ENGINEERING

![IWantToPlayAGameJigsawGIF](https://user-images.githubusercontent.com/91504420/230595657-e84fe27f-42c7-42b7-a564-e92a686b307a.gif)

Feature engineering is the process of selecting, extracting, transforming, and creating features (input variables) from raw data in order to improve the performance of machine learning models.

Feature engineering can involve several techniques such as:

Feature extraction: This involves selecting relevant features from the original dataset and extracting useful information from them.

Feature transformation: This involves transforming the features in order to improve their quality or make them easier to use in a model. Examples of transformations include scaling, normalization, and one-hot encoding.

Feature creation: This involves creating new features from the original ones in order to capture important patterns or relationships in the data. Examples of feature creation include adding interaction terms, polynomial features, or feature combinations.

Feature engineering is an important step in the machine learning pipeline as it can greatly affect the performance of the models. It requires a combination of domain knowledge, creativity, and experimentation to determine the best set of features for a given problem.

![image](https://user-images.githubusercontent.com/91504420/230595700-2d5bb2c2-060d-4330-8730-77a9a262ffd6.png)

## 14. SIGMOID FUNCTION

![ICantFunctionTheBlackHokageGIF](https://user-images.githubusercontent.com/91504420/230645853-5b83a5b8-ca41-4db4-8d76-9540e287aff3.gif)

The sigmoid function is a mathematical function that maps any input value to a value between 0 and 1, which is often used in machine learning and artificial neural networks. Specifically, the sigmoid function has an S-shaped curve and is defined as:

f(x) = 1 / (1 + e^-x)

where e is the mathematical constant approximately equal to 2.71828. The sigmoid function is useful for tasks where we want to output a probability, as it maps any real-valued input to a value between 0 and 1, which can be interpreted as a probability.

![image](https://user-images.githubusercontent.com/91504420/230646021-feda48ed-2f47-4863-816d-dec2aae2fbaf.png)

## 15. LOGISTIC REGRESSION

![PrettyCoolAwesomeGIF](https://user-images.githubusercontent.com/91504420/230646333-2ab30f9a-1ff3-4038-88c2-e5d6f98668c9.gif)

Logistic regression is a statistical method used for binary classification, which involves predicting a binary outcome (e.g., yes/no, true/false) based on one or more input variables (also known as features or predictors). It is a type of generalized linear model that uses the sigmoid function to transform the output of a linear equation into a probability value between 0 and 1.

In logistic regression, the goal is to find the best set of coefficients (weights) that minimize the difference between the predicted probabilities and the actual outcomes. This is typically done using maximum likelihood estimation or gradient descent. Once the model is trained, it can be used to make predictions on new data by feeding the input variables into the model and calculating the predicted probability of the binary outcome.

Logistic regression is a simple yet powerful method that is widely used in a variety of fields, including finance, healthcare, and marketing, among others. It is especially useful when the outcome variable is binary, and the input variables are continuous or categorical.

![image](https://user-images.githubusercontent.com/91504420/230646174-ec5544e2-afd7-41a8-8317-3296f78cd6ea.png)

![image](https://user-images.githubusercontent.com/91504420/230652897-bcfefcb9-acbd-47aa-bffa-bef4b9349b8d.png)

![image](https://user-images.githubusercontent.com/91504420/230657656-9133ef6e-0a92-4065-8d2a-48ef16404fc0.png)

![image](https://user-images.githubusercontent.com/91504420/230658121-bac2908c-fc4c-4a93-adc0-dc47ae8e1619.png)


## 16. DECISION BOUNDARY

![ItsABigDecisionToMakeGaryGrahamGIF](https://user-images.githubusercontent.com/91504420/230648329-2fb48fd8-55fa-40a9-be06-9156bf49d58c.gif)

A decision boundary is a concept in machine learning and data analysis that refers to the boundary or surface that separates different classes or groups in a dataset. In binary classification problems, the decision boundary is the line, curve, or surface that separates the data into two classes based on the values of the input variables.

The decision boundary is typically learned by a machine learning algorithm through a process of training on a labeled dataset. Once the model is trained, it can be used to make predictions on new, unlabeled data by determining which side of the decision boundary the input data falls on.

The decision boundary is influenced by various factors, including the choice of algorithm, the input features, and the complexity of the model. In some cases, the decision boundary may be linear, while in other cases, it may be nonlinear or even highly complex.

Understanding the decision boundary is important in machine learning because it can help us interpret and visualize the results of a model, as well as identify areas where the model may be uncertain or where additional data or features may be needed to improve its accuracy.

![image](https://user-images.githubusercontent.com/91504420/230649014-730e9f79-8d06-40ad-af2c-58de5a51f5b1.png)

![image](https://user-images.githubusercontent.com/91504420/230648814-372b05f0-d89a-4722-a4b6-9ba3b13440c6.png)

## 17. OVERFITTING

![GoodButNotReallyRyanHigaGIF](https://user-images.githubusercontent.com/91504420/230686012-a49d8c32-56c1-4b17-b0e3-703ca5ae1e86.gif)

Overfitting is a common problem in machine learning where a model is too complex and starts to memorize the training data instead of learning general patterns that can be applied to new, unseen data. This causes the model to perform very well on the training data but poorly on new data, which means that the model has not learned the underlying relationships in the data and has instead just memorized the noise. To prevent overfitting, techniques such as cross-validation, early stopping, regularization, and data augmentation can be used.

![image](https://user-images.githubusercontent.com/91504420/230686047-e4c0231a-d047-4c83-a257-fcfd6239c82a.png)

![image](https://user-images.githubusercontent.com/91504420/230686389-864f0da9-dc4b-4ae7-95a2-c0aeed7b5ba9.png)

## 18. ADDRESSING OVERFITTING

![StickergiantIllFixItGIF](https://user-images.githubusercontent.com/91504420/230686640-850622bb-d38b-4bf6-b3c1-0b7683f6f4cf.gif)

ddressing overfitting in machine learning is crucial for building models that generalize well to new, unseen data. Some of the techniques that can be used to prevent overfitting include:

Cross-validation: This involves splitting the data into multiple sets and training the model on each set to evaluate its performance on unseen data.

Early stopping: This technique involves stopping the training process once the model's performance on a validation set stops improving.

Regularization: This technique involves adding a penalty term to the model's loss function to prevent it from becoming too complex and overfitting the data.

Data augmentation: This involves generating additional training data by applying transformations to the existing data.

By applying these techniques, one can build models that are less likely to overfit the training data and perform well on new, unseen data.

![image](https://user-images.githubusercontent.com/91504420/230686672-a24a5b88-2521-4c46-8989-cb8d6dd0c667.png)

![image](https://user-images.githubusercontent.com/91504420/230686797-f609e9fd-10ec-46c1-a9e5-92eae39f97dc.png)

![image](https://user-images.githubusercontent.com/91504420/230686912-2f2b0d4f-1a43-4788-b6fb-508741df6651.png)

![image](https://user-images.githubusercontent.com/91504420/230687391-e3876b7d-b65e-49be-a1c4-1ad26c28de90.png)

![image](https://user-images.githubusercontent.com/91504420/230687505-5c265783-87a7-400c-9f78-e1fe94b37670.png)

![image](https://user-images.githubusercontent.com/91504420/230687845-4bd25038-f388-480b-aa52-35a8bba1a045.png)

19. NEURAL NETWORKS

![LikeItGIF](https://user-images.githubusercontent.com/91504420/231020187-32b7c8ca-c810-404a-915b-1dc9f16b1587.gif)

Neural networks are a type of machine learning algorithm inspired by the structure and function of the human brain. They consist of interconnected nodes (or "neurons") organized into layers, with each layer responsible for performing specific tasks.

During training, a neural network learns to recognize patterns in data by adjusting the weights of its connections between neurons in response to input data. This process allows the network to make predictions or classifications based on new data that it has not seen before.

Neural networks are widely used in various applications such as image and speech recognition, natural language processing, and recommendation systems. They can also be used for regression analysis, where they learn to predict numerical values based on input data.

Overall, neural networks have proven to be a powerful and flexible tool for solving a wide range of machine learning problems, and their use continues to grow in popularity.

![image](https://user-images.githubusercontent.com/91504420/231020563-1e62fbcd-6e23-483c-b10c-9c3bc6657e26.png)

![image](https://user-images.githubusercontent.com/91504420/231020610-![Uploading ItActuallyPredictsTheFutureProfRichardLenskiGIF.gif…]()
e1eea2b1-3847-40a7-8f49-eceb0182b798.png)

![image](https://user-images.githubusercontent.com/91504420/231023229-731ccc48-282c-412e-b844-79d4414a1cee.png)

![image](https://user-images.githubusercontent.com/91504420/231023134-0a205fd8-7d0d-4056-9eaf-80f4dc6f6fc5.png)

![image](https://user-images.githubusercontent.com/91504420/231023362-2a4fd6fa-22fb-4874-ab56-99ab0e284d04.png)


20. FORWARD PROPAGATION

![IHavePredictedItFamilyFeudCanadaGIF](https://user-images.githubusercontent.com/91504420/231021146-3e3bb4a3-6579-4102-878a-b8b737d2e8e1.gif)

Forward propagation is the process by which a neural network calculates its output based on the input data. During forward propagation, the input data is passed through the layers of the network, and each neuron in each layer performs a weighted sum of its inputs, adds a bias term, and applies an activation function to produce an output. The output from each neuron in one layer serves as input to the next layer, until the final layer produces the network's output.

The weights and biases in the network are learned during training, using an optimization algorithm that adjusts them to minimize the difference between the network's predicted output and the actual output. The optimization algorithm typically involves backpropagation, in which the error between the predicted and actual output is propagated backward through the network to adjust the weights and biases.

Overall, forward propagation is a key step in the functioning of a neural network, as it allows the network to make predictions based on input data, and the accuracy of those predictions depends on the quality of the weights and biases learned during training.


![image](https://user-images.githubusercontent.com/91504420/231021462-5b08f738-2287-4b25-ade8-3f265d0e728c.png)

## 21. TENSORFLOW

![CodingGIF](https://user-images.githubusercontent.com/91504420/231023570-7db1fd04-c688-4926-a846-0dbeb488b0f1.gif)

TensorFlow is an open-source machine learning library developed by Google that allows developers to build, train, and deploy machine learning models. It provides a flexible, high-level API for building neural networks and other machine learning models, and supports a wide range of model architectures and data types.

TensorFlow uses a dataflow graph model to represent computations as a series of nodes and edges, with tensors (multi-dimensional arrays) flowing between them. This allows for efficient parallel execution of computations, making it well-suited for large-scale machine learning applications.

The library provides a range of tools and interfaces, including low-level APIs for building custom models, high-level APIs for easy model construction and training, and a variety of pre-trained models and tools for common machine learning tasks such as image classification, object detection, and natural language processing.

Overall, TensorFlow is a powerful and widely-used tool in the field of machine learning and has enabled many researchers and developers to build and deploy sophisticated machine learning models in a wide range of applications.

![image](https://user-images.githubusercontent.com/91504420/231024196-50297cb5-f50e-4806-a238-829e4a753fbb.png)

![image](https://user-images.githubusercontent.com/91504420/231024242-0ad2db03-a60c-4266-9ebd-3191baadf04d.png)


<!-- Contact -->
# :handshake: Contact

<p align="left">
<a href="https://twitter.com/liron_mizrahi" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/twitter.svg" alt="liron_mizrahi" height="50" width="60" /></a>
<a href="https://instagram.com/liron.mizrhai1234" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/instagram.svg" alt="liron.mizrhai1234" height="50" width="60" /></a>
<a href="https://www.linkedin.com/in/%D7%9C%D7%99%D7%A8%D7%95%D7%9F-%D7%9E%D7%96%D7%A8%D7%97%D7%99-1050b421a/">
  <img align="left" alt="liron LinkedIN" height="50" width="60" src="https://raw.githubusercontent.com/peterthehan/peterthehan/master/assets/linkedin.svg" />
</a>
</p>

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<!-- Acknowledgements -->
# :gem: Acknowledgements

Links to information that helped me during construction and learning:
 - [python3](https://docs.python.org/3/)

<!-- About the authors -->
## :telephone: About the authors

 - Liron Mizarhi - Navy soldier and programmer

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<!-- Project status -->
## :octocat: Project Status

### Project is: In Progress!

<p align="right">(<a href="#readme-top">back to top</a>)</p>
